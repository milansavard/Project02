{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Milan Savard and Damien Wiese**\n",
    "\n",
    "Fall 2024\n",
    "\n",
    "CS 343: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from adaline import Adaline\n",
    "\n",
    "# Set the color style so that Professor Layton can see your plots\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "# Make the font size larger\n",
    "plt.show()\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Turn off scientific notation when printing\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 | Single-Layer Networks\n",
    "\n",
    "In this project, you will implement single-layer neural networks that includes the same fundamental components as larger multi-layer networks. You will get familiar with the most common \"neural network workflow\":\n",
    "- preprocessing data\n",
    "- training a neural network\n",
    "- evaluating test data\n",
    "- examining performance metrics\n",
    "\n",
    "We will take advantage of the relative simplicity of single-layer neural networks to analyze and visualize the learned class decision boundaries (*this is more difficult and less intuitive in more complex neural networks that we will study!*).\n",
    "\n",
    "You will also investigate how the same neural network architecture can be used for both classification and regression with only modest changes.\n",
    "\n",
    "#### Reminders\n",
    "\n",
    "- In this class, use `numpy ndarray` (`np.array()`), not Numpy Matrix.\n",
    "- To help safeguard against data loss when working in a jupyter notebook, make sure the notebook is `Trusted` (Top right corner of notebook when opened in your browser). This will ensure your work autosaves. **I still recommend manually saving at least every few minutes with (Control+S / Cmd+S)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the ADAptive LInear NEuron (ADALINE) network for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Task 1, complete the methods of the `Adaline` class in `adaline.py`. This includes:\n",
    "\n",
    "- `net_input(self, features)`\n",
    "- `activation(self, net_in)`\n",
    "- `loss(self, errors)`\n",
    "- `accuracy(self, y, y_pred)`\n",
    "- `gradient(self, errors, features)`\n",
    "\n",
    "- `predict(self, features)`\n",
    "- `fit(self, features, y, n_epochs, lr)`\n",
    "\n",
    "**Important:** Before starting, read through the method descriptions and expected inputs/outputs. It probably would be a good idea to tackle simpler/smaller methods first, then use them in more complex ones. For example, it may be a good idea to work on `net_input` first because it is required to complete `fit`. There is test code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a summary of the ADALINE network equations\n",
    "\n",
    "##### Net input\n",
    "\n",
    "$\\vec{x}_i$ is one of the $N$ data sample vectors from the dataset matrix $A$. That is, `x_i.shape = (M,)`.\n",
    "\n",
    "$$\\text{netIn}_i = \\sum_{j=1}^M x_{ij} w_j + b$$\n",
    "\n",
    "##### Net activation\n",
    "\n",
    "Identity function:\n",
    "\n",
    "$$ f(x) = x $$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\\text{netAct}_i = \\text{netIn}_i$$\n",
    "\n",
    "\n",
    "##### Loss: Sum of squared error\n",
    "\n",
    "$$L(\\vec{w}) = \\frac{1}{2} \\sum_{i=1}^N \\left ( y_i - \\text{netAct}_i \\right )^2 $$\n",
    "\n",
    "##### Gradient (bias)\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b} = -\\sum_{i=1}^N \\left ( y_i - \\text{netAct}_i \\right )$$\n",
    "\n",
    "##### Gradient (wts)\n",
    "\n",
    "Below, $x_{ij}$ is the $j^{th}$ feature of the data sample vector $\\vec{x}_i$.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_j} = -\\sum_{i=1}^N \\left ( y_i - \\text{netAct}_i \\right ) x_{ij}$$\n",
    "\n",
    "##### Gradient descent (delta rule)\n",
    "\n",
    "$$b(t+1) = b(t) - \\eta \\frac{\\partial L}{\\partial b}$$\n",
    "$$w_j(t+1) = w_j(t) - \\eta \\frac{\\partial L}{\\partial w_j}$$\n",
    "\n",
    "above $\\eta$ is the learning rate, and $N$ is the training set (number of data samples in training epoch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Test your ADALINE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Adaline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `loss` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "randErrors = np.array([-0.535,  0.222, -0.391,  0.196, -0.29 , -1.953])\n",
    "net_act = rng.random(len(randErrors))\n",
    "debugLoss = net.loss(randErrors, net_act)\n",
    "print(f'Your loss is {debugLoss:.4f} and it should be 5.5122')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `accuracy` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randClasses1 = np.where(randErrors >= 0, 1, -1)\n",
    "randClasses2 = np.roll(randClasses1, 1)\n",
    "acc1 = net.accuracy(randClasses1, randClasses1)\n",
    "acc2 = net.accuracy(randClasses1, randClasses2)\n",
    "print(f'Test 1: Your accuracy is {acc1} and it should be 1.0')\n",
    "print(f'Test 2: Your accuracy is {acc2:.4f} and it should be 0.3333')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `gradient` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "randFeatures = rng.normal(loc=0, scale=1, size=(15,4))\n",
    "randErrors1 = rng.normal(loc=0, scale=1, size=(15,))\n",
    "randBiasGrad, randWtGrad = net.gradient(randErrors1, randFeatures)\n",
    "print(f'Test 1: Your bias gradient is {randBiasGrad:.3f} and it should be -3.985')\n",
    "print(f'Test 2: Your wt gradient is {randWtGrad} and it should be [-5.231 -0.2    6.001  6.55 ]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `predict` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "inputs = rng.standard_normal([10, 4])\n",
    "net.wts = rng.standard_normal(4)\n",
    "net.b = rng.standard_normal(1)\n",
    "y_pred = net.predict(inputs)\n",
    "print(f'Your predicted classes are {y_pred}.\\n            They should be [ 1  1 -1  1  1  1 -1 -1  1  1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `fit` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "net = Adaline()\n",
    "inputs = rng.standard_normal([9, 6])\n",
    "y = np.sign(rng.standard_normal(9))\n",
    "loss, acc = net.fit(inputs, y, r_seed=0)\n",
    "print(f'Your end-of-training loss / accuracy are\\n{loss[-1]:.4f} / {acc[-1]:.4f}.\\nThey should be\\n0.5495 / 1.0000.')\n",
    "print(f'Your wts after training are:\\n{net.get_wts()}\\nand should be\\n[-0.288  1.361 -0.203 -0.084 -0.245 -0.501]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Load in and preprocess old faithful data\n",
    "\n",
    "In this task, you will be working with the old faithful dataset. Here is a description of the dataset:\n",
    "\n",
    "    Waiting time between eruptions and the duration of the eruption for the Old Faithful geyser in Yellowstone National Park, Wyoming, USA.\n",
    "\n",
    "    Variables:\n",
    "    ----------\n",
    "    sample     numeric      Measurement number\n",
    "    eruptions  numeric      Eruption time in mins\n",
    "    waiting    numeric      Waiting time to next eruption\n",
    "    severe     categorical  Whether the eruption was \"severe\"\n",
    "                            (+1: severe, -1 not severe)\n",
    "\n",
    "Write code to do the following in the below cell.\n",
    "\n",
    "1. Load in `old_faithful.csv`, represent the data using a ndarray. Select the `eruptions` and `waiting` variables for your features.  Shape = [Num samps, Num features] = [272, 2].\n",
    "2. Assign the output classes (**severe**) to a separate 1D ndarray vector. Shape=(272,)\n",
    "3. Preprocess the data by performing min-max normalization across features (i.e. \"per-variable\"/\"separately\").\n",
    "4. Use matplotlib to create a scatter plot of the normalized data, color-coding data points according to their class\n",
    "5. I suggest using pandas, but you're welcome to do this however you like.\n",
    "\n",
    "**Make sure that executing the below cell results in an inline scatter plot, color-coded by class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebbf420db2b4a7ad7409405d1c81266b",
     "grade": false,
     "grade_id": "cell-2e71ddd56a368c66",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Train ADALINE on normalized Old Faithful data using default hyperparameters (i.e. learning rate, epochs)\n",
    "\n",
    "Print out the final loss and accuracy, then use the provided function to plot your training results inline in the below cell.\n",
    "\n",
    "By the final epoch, training loss should reach ~11.36 and accuracy ~100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d26f845b90cfc3d7f62d86e8550f2a4",
     "grade": false,
     "grade_id": "cell-9e16dff5a56e3fc7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72f671eb82b5ff91e154ac08497f95e4",
     "grade": false,
     "grade_id": "cell-5fde270f532964cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_adaline_train(net, loss_list, acc_list, plotMarkers=False, title='ADALINE'):\n",
    "    '''Helper plotting function provided for you.'''\n",
    "    n_epochs = len(loss_list)\n",
    "\n",
    "    x = np.arange(1, n_epochs+1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "    fig.suptitle(f'{title} ({n_epochs} epochs)')\n",
    "\n",
    "    curveStr = '-r'\n",
    "    if plotMarkers:\n",
    "        curveStr += 'o'\n",
    "\n",
    "    ax1.plot(x, loss_list, curveStr)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (Sum squared error)')\n",
    "    ax2.plot(x, acc_list, curveStr)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "**Question 1.** Based on your loss and accuracy curves, does it look like your network learned to classify the old faithful data? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d52c874a0a287dbc74993abb3e427ee5",
     "grade": true,
     "grade_id": "cell-668dbfda237356e7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Feature scaling and hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Feature scaling\n",
    "\n",
    "Copy your code from Task 1 to import the Old Faithful data, but this time don't normalize before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b386801bcbcfaf18a03c602758b21f22",
     "grade": false,
     "grade_id": "cell-76c411907ef7ca73",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "**Question 2.** What happens to the loss when we don't normalize the features before training? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73e7d105fe8c24c41c4ed5fa71d67120",
     "grade": true,
     "grade_id": "cell-8be5c482e46faf17",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Test how individually standardizing your features affects the rate at which loss decreases over epochs\n",
    "\n",
    "1. Write code in the cell below to train the network on standardized features. Recall that standardizing a variable means applying the transformation $\\frac{x - \\mu}{\\sigma}$. The mean and standard deviation should be computed over the entire dataset and separately per feature.\n",
    "2. Plot the loss and accuracy.\n",
    "\n",
    "**The cell should generate an inline pair of plots when executed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45da50a934af3f1c65606be7c1f669fe",
     "grade": false,
     "grade_id": "cell-b644ed4e53f5b90f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "**Question 3.** Explain the similarities/differences in loss and accuracy curves between these plots and those that you made in Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fad9b02d6d479b58d6cc2b3edbf67b03",
     "grade": true,
     "grade_id": "cell-ffe6406af9a6befa",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Influence of learning rate\n",
    "\n",
    "This subtask focuses on the influence of learning rate (a model **hyperparameter**) on the quality of neural network training.\n",
    "\n",
    "#### Questions\n",
    "\n",
    "**Question 4:** Make small changes to the learning rate hyperparameter below. How does it affect the loss? **Make 1+ plots that clearly support what you notice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cd9fa21e8e270c596a5d8214603e98b",
     "grade": true,
     "grade_id": "cell-94330c7185b337e2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce0c4d4e8c9dc8640ff3d64a95fd2c17",
     "grade": false,
     "grade_id": "cell-00fa9c695170ebb2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** What happens to the loss if the learning rate is increased by several orders of magnitude? Why? **Make 1+ plots that clearly support what you notice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 5:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed5210ca6dbe41b8579616b1f52a8afd",
     "grade": true,
     "grade_id": "cell-b80f7ce5b493e5e2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4036e803692f8b8627ac172d144227aa",
     "grade": false,
     "grade_id": "cell-24dcb5ce415bdbb5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Visualize class boundaries\n",
    "\n",
    "For this subtask, you will plot the boundary between points (`eruptions`, `waiting` feature pairs) that get classified as severe (+1) or not (-1). To get there, fill in the blanks and answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "123f7866f5de424dadd45d9f90593ec8",
     "grade": false,
     "grade_id": "cell-b916993baf03cbc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Print your learned wts and bias here after training net on standardized samples\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "**Question 6.** What is the meaning of each of the above learned weights with respect to the variables/features in the dataset?\n",
    "\n",
    "*Hint:* Look at your `net_in` equation, look at the features that you feed into the model, look at the scatterplot you made in 1b, think about what features are present in a single training sample.\n",
    "\n",
    "**Question 7.** Which feature / weight index corresponds to the \"y axis value\" in your scatterplot from 1b?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 6:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09752b74e54c995fb26b51eae8794831",
     "grade": true,
     "grade_id": "cell-c05e0a5f061ed14e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 7:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "535b7ff30df50518e9ec0446d68768a9",
     "grade": true,
     "grade_id": "cell-044b8ddf73bc28da",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform weights for plotting\n",
    "\n",
    "The class boundary equation is $0 = w_0 + w_1 \\times x_i + w_2 \\times y_i$ for sample $i$ in our data ($i$ goes to 272). But to plot it, we need an equation that looks like $y_i = m \\times x_i + b$ where $m$ and $b$ are some combinations of our weights.\n",
    "\n",
    "1. Scale the weights so that the one corresponding to the \"y value\" is set to 1, then solve for $y$ (*It might be helpful to work this out by hand*). Once you do, adjust the sign/scale of your weights in code so they match up with the equation you wrote out by hand ( of form $y_i = m \\times x_i + b$). **Be careful about the order in which you manipulate the bias and weight values when setting up your equation.**\n",
    "2. Once you're done, have the cell below print your transformed weights/bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a60aae128a84f7743fd83fc7b36d079",
     "grade": false,
     "grade_id": "cell-7dc8dd73f5385a01",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, sample 50 equally spaced x values from -1.5 to 1.5 for plotting the class boundary. Given the `x_i` values, generate `y_i` values using the equation $y_i = m \\times x_i + b$ (using your transformed weights from above). \n",
    "\n",
    "**Executing the code below should produce a graph that clearly shows this class boundary superimposed on your data scatter plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50cf7efdf2a91f9bd99d21713b82850e",
     "grade": false,
     "grade_id": "cell-5768786c4a9b740c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Perceptron: A neural network with a different activation function\n",
    "\n",
    "In this task, you will apply ADALINE to a larger dataset ([Ionosphere dataset](https://archive.ics.uci.edu/dataset/52/ionosphere)) and compare the performance of ADALINE with another binary classification neural network . A **Perceptron** is a single-layer neural network that works exactly the same as ADALINE, except it uses a different network activation function (`netAct`). The activation function computes the `netAct` as follows:\n",
    "\n",
    "$$\\text{netAct}_i = f(\\text{netIn}_i) = 1  \\text{ if netIn}_i \\geq 0$$\n",
    "$$\\text{netAct}_i = f(\\text{netIn}_i) = -1 \\text{ if netIn}_i < 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Implement and test a Perceptron\n",
    "\n",
    "1. Create a new class in `adaline.py` that will represent your Perceptron classifier. It should inherit from `Adaline`. Override/write any necessary functions. **Hint:** This should be really quick, short, and simple.\n",
    "2. In the cell below, train your Perceptron on the same standardized Old Faithful data by making loss and accuracy plots like you have been using in previous tasks (*though you should replace the default title in `plot_adaline_train` with Perceptron*).\n",
    "\n",
    "If everything is working, you should get very similar results with your Perceptron as above with ADALINE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaline import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea88330babb26e255386ec6d631c5f34",
     "grade": false,
     "grade_id": "cell-c5e4f1d6bdf17062",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6d89a5cb35857570adc59b3043b00a8",
     "grade": false,
     "grade_id": "cell-752878ea01b383e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Compare performance between ADALINE and Perceptron on Ionosphere dataset\n",
    "\n",
    "Your goal is to train, compare, and analyze the performance of your ADALINE and Perceptron networks on the Ionosphere dataset.\n",
    "\n",
    "The [Ionosphere dataset](https://archive.ics.uci.edu/dataset/52/ionosphere) is radar signal data collected in Goose Bay, Labrador. It is a more complex dataset than old faithful, with 33 features (but still 2 classes). The class values are coded 'g' for good radar signal and 'b' for bad radar signal.\n",
    "\n",
    "**Please download the CSV file from the CS343 project website (not above UCI link)** — I have slightly modified the dataset for your convenience.\n",
    "\n",
    "**TODO:**\n",
    "1. Load in and normalize the Ionosphere dataset by standardization. Note that there are no headers in the CSV file and the class values are specified in the last column — **make sure that they are coded properly** (i.e. $-1$ and $+1$).\n",
    "2. In the cell below, use the provided `plot_nets_train` helper function to create a 1x2 plot showing training loss and accuracy of the two networks.\n",
    "\n",
    "Your goal is to play with the hyperparameters until both networks **start** plateauing in accuracy. Your accuracy doesn't literally need to stop increasing — you just want the visual impression of it doing so. Don't train the networks too long so that you miss the early trend in loss and/or accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nets_train(loss_lists, acc_lists, net_names, plotMarkers=False):\n",
    "    '''Creates a 1x2 grid of plots showing loss over epochs (left column) and\n",
    "    accuracy over epochs (right column) for one or more network (num_nets in total).\n",
    "    Generalizes `plot_adaline_train` for multiple trained networks.\n",
    "\n",
    "    For example, in the case of two networks (e.g. adaline and perceptron; num_nets=2),\n",
    "    there would be two curves in each of the two plots.\n",
    "\n",
    "    Put differently, the following function call would produce the same pair of plots you've\n",
    "    been getting up until this point with a single adaline network:\n",
    "        plot_adaline_train(loss_lists[0], acc_lists[0])\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    loss_lists: Python lists of ndarrays. len(loss_lists) = num_nets. len(loss_lists[0]) = n_epochs.\n",
    "        This would be a list of the loss histories for each of the nets being plotted.\n",
    "    acc_lists: Python lists of ndarrays. len(acc_lists) = num_nets. len(acc_lists[0]) = n_epochs.\n",
    "        This would be a list of the accuracy histories for each of the nets being plotted.\n",
    "    net_names: Python list of str. len(net_names) = num_nets.\n",
    "        Identifying names of each net (e.g. for legend).\n",
    "    plotMarkers: boolean.\n",
    "        Should we draw a plot marker at each epoch on each curve?\n",
    "    '''\n",
    "    n_nets = len(net_names)\n",
    "    n_epochs = len(loss_lists[0])\n",
    "\n",
    "    colors = ['orange', 'blue', 'red']\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "    fig.suptitle(f'{n_nets} networks trained for ({n_epochs} epochs)')\n",
    "\n",
    "    for loss_list, acc_list, color in zip(loss_lists, acc_lists, colors):\n",
    "        x = np.arange(1, n_epochs+1)\n",
    "\n",
    "        curveStr = '-'\n",
    "        if plotMarkers:\n",
    "            curveStr += 'o'\n",
    "\n",
    "        ax1.plot(x, loss_list, curveStr, c=color)\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss (Sum squared error)')\n",
    "        ax2.plot(x, acc_list, curveStr, c=color)\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "\n",
    "    plt.legend(net_names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31ee0e15bd46849c652cf59c041a4cb0",
     "grade": false,
     "grade_id": "cell-8c2261e5b88667a5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "**Question 8.** What accuracy are you able to achieve on the Ionosphere dataset with each networks at the end of training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 8:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee0b5d695ae1a88248353ff804d46c67",
     "grade": true,
     "grade_id": "cell-45729a7c24e0f5b4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Influence of learning rate\n",
    "\n",
    "Now let's analyze the effect learning rate on the nets. Make plots that illustrate the effect of the following on ADALINE and Perceptron learning.\n",
    "\n",
    "1. learning rate increased by 1+ order of magnitude in each network.\n",
    "2. learning rate decreased by 1+ order of magnitude in each network. *You will likely need to increase the number of training epochs too.*\n",
    "\n",
    "#### Questions\n",
    "\n",
    "**Question 9:** Interpret the difference in behavior between the two nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2f7a3a3d7fc916d8942402bb3ca7509",
     "grade": false,
     "grade_id": "cell-18758f19b6c2a4c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9dcf66db433c329618c3310c84cbe6a",
     "grade": false,
     "grade_id": "cell-f8bbef8effc57636",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 9:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83fee8560249ce4211b1eb2c64545cab",
     "grade": true,
     "grade_id": "cell-c9131e651a30d7fd",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Plotting classifications\n",
    "\n",
    "Make two scatter plots (one per network) showing the feature at index 4 on x-axis and the feature at index 19 on the y-axis. Samples should be color coded one of two colors: whether the class was correctly or incorrectly predicted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8012c7b3b5325c9e8d123b62e360dfc0",
     "grade": false,
     "grade_id": "cell-6fa3f319209e036b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Questions\n",
    "\n",
    "**Question 10:** In your scatter plots showing correct and incorrect sample classifications, how is it possible that misclassifications are so dispersed and do not appear to either side of a simple boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 10:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffb4b7e78c13bce58e87bc24d74dcd69",
     "grade": true,
     "grade_id": "cell-743447147924ce33",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
